b'Face Recognition Using Facial Symmetry \n \nAv\ninash Kumar Singh, G. C. Nandi \nRobotics & Artificial Intelligence Lab. \nIndian Institute of Information Technology, Allahabad, India \n{avinashkumarsingh1986, gcnandi}@gmail.com \n \nABSTRACT  \nFa\nce is the most frequently used biometric trait after fingerprint. \nIts applicability made it popular in different areas such as Human \nRobot Interaction (HRI), Security Authentication, and \nSurveillance to name a few. Face recognition concept is based on \ntwo major blocks, training and testing. Usually training is done \noffline while testing is performed in real time scenario. As the size \nof the database increases, the recognition rate (time taken by \nsystem to recognize) increases. The rate of recognition is directly \nproportional to the size of the database and the dimension of the \nimages. Human faces have the vertical symmetry; hence we \nutilized this feature and proposed a half way face recognition \napproach. Experimental verification on both the full faces and the \nhalf faces shows that half faces are also sufficient for recognizing \nthe person. For verifying the efficiency of the approach, we have \napplied PCA (Principle Component Analysis) on both, the full \nfaces and half faces, and have found that in both the cases, \naccuracy is almost same. But the recognition rate of half faces is \njust the half of the full faces. \nCategories and Subject Descriptors \nI.\n4.7 [ IMAGE PROCESSING AND COMPUTER VISION ]: \nFeature Measurement\xe2\x80\x93 Feature representation, Size and shape, \nProjections.  \nGeneral Terms  \nRe\nliability, Experimentation, Security, Verification. \nKeywords  \nFa\nce Recognition, PCA, Facial Symmetry. \n1. INTRODUCTION \n \n\xe2\x80\x98Biometrics is defined as the measurement of life. It is composed \nof\n two words \xe2\x80\x93 bio means life and metric means measurement. It \nconsists of some methods to uniquely recognize human being, \nbased on their physiological and behavioral traits. Face \nrecognition is the physiological biometrics technique, which does \nnot require any direct cooperation of human being [2]. Every \nhuman being has some common physiological traits like ears, iris, \nface and fingerprints but due to different geometrical \nrepresentation of these, they are unique for each person out of \nwhich we limit ourselves to face alone. Each human face has \ncertain unique identification traits that make them distinguishable from others. Faces play a magnificent role in several areas like \naccess control, surveillance and human robot interaction system \netc., as they represent rich source of information. The history of \nthe face recognition technology started from late 1960s with the \ndevelopment of the semi-automated system, where administrator \nneeds to locate the feature points (eyes, nose, mouth, etc.) [8]. \nLater recognition is performed by calculating the distance \nbetween the reference point of probe image and feature points of \ngallery images. Later advancement in this direction, suggested two \nways of face recognition (a) based on face geometry (b) based on \ntemplate. Geometry based methods used face geometry to \ndistinguish the person, while template based methods used image \nintensity matrix for comparing the images and recognizing the \nperson [3]. Intensity matrices of faces are basically dependent on \nthe image dimension, and the values of the matrix depend on the \nformat of the image (like RGB, Gray, and Black & White). \nTherefore, processing such a big dimension matrix requires much \ntime. Recognition is performed in real time: therefore recognition \ntechniques should be faster and accurate.   \nIn 1996, two researchers David O\xe2\x80\x99Mara and Robyn Owens [1] \nfound a new way which could be used for the purpose of face \nrecognition. They proposed a concept of bilateral symmetry in \ndigital images. With the help of a dominant hyper plane they \ndivided the objects in the image into two parts, so that each one \nlooked like a mirror image of the other. Later, this approach of \nfacial symmetry was also used by Xin Chen et.al [4]. They \ndesigned a fully automatic tool based on gray level difference \nhistogram to define the symmetry in faces, but the disadvantage of \ntheir algorithm is it cannot define the symmetry when faces are \nnot perfectly aligned in front of the camera. Human faces are symmetrical or not still a topic of debate, because the answer \nvaries from person to person. Due to some environmental issues \nor due to some diseases like craniofacial deformity, some people \ndo not have perfect bilateral symmetry. Some Children are born \nwith these deformities, while others acquire it by mental trauma or \nother diseases.  Same question in this regard has been well \naddressed in [6]. But the successful implementation of facial \nsymmetry in 3D faces to handle pose variations by Georgios \nPassalis et al. [5] motivated us to proceed in that direction. \nTherefore, in this paper, we have first defined the bilateral symmetry on ORL database [12], and on the basis of symmetry of the full faces, we have extracted the half faces. Later, these half \nfaces are used for the training and testing purpose. The \nexperimental results using the PCA on both the full faces and the \nhalf faces have strengthened our hypothesis.  \nThis paper is structured as follows: Section 2 describes the \nbackground details of PCA and provides the pseudo code of the \nmethod. In Section 3, we proposed face recognition method using \nface symmetry. Section 4 shows experimental verification of our \napproach and the comparison of their results with full face  Permission to make digital or hard copies of all or part of this work for \npe\nrsonal or classroom use is granted without fee provided that copies are \nnot made or distributed for profit or commercial advantage and that \ncopies bear this notice and the full citation on the first page. To copy \notherwise, or republish, to post on servers or to redistribute to lists, \nrequires prior specific permission and/or a fee. \nCCSEIT-12 , October 26-28, 2012, Coimbatore [Tamil nadu, India] \nCopyright \xc2\xa9 2012 ACM 978-1-4503-1310-0/12/10\xe2\x80\xa6$10.00. \n550\n'
b'recognition. In section 5, we conclude the paper with its \ncontribution towards the face biometrics and its future prospects. \n2. PCA Algorithm for Face Recognition   \nP\nCA is a mathematical tool designed by Karl Pearson in 1901 to \nre\nduce the dimension of large datasets. The primary motivation \nfor designing this tool was to represent the whole information \n(Big data) within a small entity. These small entities are known as \nprinciple components. Principle components are considered to be \nthe most promising features of the datasets.  \nWe have presented PCA in the algorithmic way so that it would \nbe easier to understand how it practically works when face \nrecognition is used. The algorithm is divided into two parts (a) \nTraining and (b) Testing. Generally testing is performed offline \nand testing is performed in real time scenario. The mathematics of \nPCA can be found in literature [9][10][11]. So we have tried to \nprovide a practical approach towards the understating and \nimplementation of PCA. The given algorithm is influenced by \nMathew Turk and Ales Pentaln [7] who have proposed PCA for \nfaces in early 1991.  They presented both, a mathematical view \nand a simplified way in terms of algorithm to better understand of \nthis technique. \n2.1 PCA for training the System \nS\ntep1:  Generating Face Database  \n F\nor each image in N \n Img=read image(ImageName); \n       Img_db=img; \nend \nStep2.   Find Co-variance of the face  \n M=mean(Img_db); \n For each image in n \n Var=Img_db(i)-m; \nEnd \nCo_Var=VarT *Var; \nStep4.   Finding Eigen Vectors and Eigen Values \n [V D]=eig(Co_Var); \nStep5.   Choosing Best Eigen Vectors \n For i=1 to Col_Size(D) \n If(D(i,i)>TH) //TH=Threshold for selecting the  \n Best_Vect=V(:,i) // best eigen vectors \n end \nStep6.   Generating EigenFaces \n EigenFaces=Var * Best_Vect; \nStep7.   Generating ProjectedFaces \n For each image in N \n ProjectedEigenFaces = EigenFacesT*Var(:,i); \n \n end 2.2 PCA for Testing the System \nS\ntep1:  Reading the Test Image  \n I\nmg=read image(ImageName);        \nStep2.   Mean Allignment  \n Img=Img-m; \nStep3.   Generating ProjectTestFace \nProjectedTestFace = EigenFacesT*Img; \n \nStep4. Finding distance between ProjectedFaces and        \nPr\nojectedTestFace \n For each image in N \n Dist=min(ProjectedTestFace, \nProjectedEigenFaces(:,i)); \n end //Minimum distance leads to the matched image \n3. Proposed Approach \nT\nhe proposed model is divided into two parts: first part measures \nth\ne symmetry of the face while the second part uses this feature \nand utilizes it into the face recognition. \n \nFigure 1: Description of Proposed Model \nFigure 1 shows the description of our work, each block has its \nsignificance. The first block deals with the pre-processing of the \nface images. It detects the face from the given image (either from \ninput image or directly from camera). Then it extracts the face and \nsave it separately, later scaling, RGB to Gray Conversion, \n551'
