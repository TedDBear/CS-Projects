b'BOD-tree: An One-Dimensional Balanced Indexing Algorithm\nRuijie Tian\ntrj@dlmu.edu.cn\nDalian Maritime University\nDalian, Liaoning, ChinaWeishi Zhang\xe2\x88\x97\nDalian Maritime University\nDalian, Liaoning, ChinaFei Wang\nDalian Maritime University\nDalian, Liaoning, China\nABSTRACT\nThe rapid growth oftrajectory data has prompted researchers to\ndevelop multiple large trajectory data management systems. One\nof the fundamental requirements of all these systems, regardless\nof their architecture, is to partition data efficiently between ma-\nchines. In the typical query operations of tracks, the query on ID is\na frequent operation of track query, such as ID time range query,\nID space range query, etc. A widely used ID indexing technique\nis to reuse an existing search tree, such as a Kd-tree, by building\na temporary tree for the input samples and using its leaf nodes\nas partition boundaries. However, we show in this paper that this\napproach has significant limitations. To overcome these limitations,\nwe propose a new indexing, BOD-tree, which inherits the main fea-\ntures of the Kd-tree and can also partition the dataset into multiple\nbalanced splits. We test the method on real datasets, and extensive\nexperiments show that our algorithm can improve resource usage\nefficiency.\nCCS CONCEPTS\n\xe2\x80\xa2Information systems \xe2\x86\x92Data management systems .\nKEYWORDS\none-dimensional data, Kd-tree, balanced indexing\nACM Reference Format:\nRuijie Tian, Weishi Zhang, and Fei Wang. 2022. BOD-tree: An One-Dimensional\nBalanced Indexing Algorithm. In AISS \xe2\x80\x994: International Conference on Ad-\nvanced Information Science and System, November 25\xe2\x80\x9327, 2022, Sanya, China.\nACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3573834.3574493\nA general-purpose distributed system can handle typical batch tasks.\nBecause the built-in partitioning method uses the number of bytes\nto divide the data file into fixed-size non-indexed blocks. However,\nbuilt-in partitioning methods may result in performance degrada-\ntion for applications that require partitioning if selectively queried\nbased on the ID dimension of the data [ 3,4]. Because built-in parti-\ntioning ignores the distribution of dimensions in the dataset. The\ncommunication and synchronization overhead of selectivity queries\n\xe2\x88\x97Corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nAISS \xe2\x80\x994, November 25\xe2\x80\x9327, 2022, Sanya, China\n\xc2\xa92022 Association for Computing Machinery.\nACM ISBN 978-1-4503-9793-3/22/11. . . $15.00\nhttps://doi.org/10.1145/3573834.3574493is assumed to be handled implicitly by the selection of proper parti-\ntioning and parallel computation schemes at the beginning, so that\npartitioning balanced is the main metric explicitly considered.\nFor example, consider a trajectory dataset. Each track data con-\ntains track ID, vehicle ID, spatial information, timestamp and some\nother attributes. It can be based on temporal ID (how many tracks\ndoes a taxi have on a particular day?) or spatial ID (how many\ntracks does a taxi produce in a particular spatial area?) or ID (find\nall track data for a particular taxi).\nIn the application of trajectory data, one of the most frequent and\ncritical operations is the ID query. However, most of the existing\ndistributed trajectory data management systems mainly focus on\nthe index construction of the spatiotemporal dimension, ignoring\nthe index research on the ID dimension, that is, partitioning data\nacross machines in an ID-aware manner. Considering a conven-\ntional approach, we utilize the Kd-tree implemented in ST-Hadoop\n[1] to build the index on the ID dimension. The method selects a\nsmall sample from the input to determine the ID distribution, di-\nvides the sample using a Kd-tree algorithm, and then partitions the\nentire data using the boundaries of the leaf nodes. Fig. 1(a) shows\nan example of a Kd-tree-based index, where each data partition is\nrepresented by a green circle. Indexes based on Kd-trees are very at-\ntractive due to their simplicity and excellent load balancing, which\nis very important for distributed applications.\nAlthough widely used, Kd-tree-based indexes have significant\nlimitations in their quality as duplicate ID indexes, which is evident\nin Fig. 1(a). In fact, anyone familiar with Kd-tree [ 2] indexes will\nimmediately find that Kd-trees are only suitable for index building\nwith unique IDs, and can cause severe partition skew for duplicate\nIDs, thereby reducing the quality of the index, i.e. query perfor-\nmance. Therefore, we revisit Kd-tree indexes and investigate how\nto improve Kd-trees to support indexing of duplicate IDs.\nIn this paper, we investigate two general approaches that employ\nexisting Kd-trees, a black-box approach and a white-box approach.\nIn the black-box approach, we select input samples, load them into\nany standard Kd-tree, and use their leaf nodes as the minimum\nboundary segments (MBS) of the index partition. This approach is\nsimple to use, however, it has two major limitations that motivate us\nto propose a novel white-box implementation of a short description.\nThe first limitation of the black-box implementation is that Kd-\ntrees can produce leaf nodes that vary widely in size when indexing\nduplicate IDs, resulting in unbalanced load on a distributed index\nsuch as the one in Fig 1(b). The second limitation is that Kd-trees are\nbuilt on not necessarily covering the entire input sample. As a result,\nwhen the actual data is partitioned, it may happen that records\nare allocated to full partitions, which will cause the partitions to\nexpand, and they may create overlapping partitions. This is a serious\nperformance issue for ID queries.\n'
b'AISS \xe2\x80\x994, November 25\xe2\x80\x9327, 2022, Sanya, China Tian, et al.\n9 \n5 13 \n3 7 11 15 \nP3 P1 P7 P5 \xe2\x89\xa59 \n\xe2\x89\xa55 \nP2 P4 P6 P8 \n(a) Kd-tree index with unique ID\n3 \n3 13 \n3 3 11 15 \nP3 P1 P7 P5 \xe2\x89\xa53 \n\xe2\x89\xa53 \nP2 P4 P6 P8 \n(b) Kd-tree index with duplicate ID\nFigure 1: Two different indexing strategies.\nTo overcome the limitations of black-box implementation, this\npaper proposes a white-box approach to Kd-trees, inheriting their\nmain features while overcoming the above limitations, which we\ncall BOD-tree ( Balanced One-Dimensional tree) to distinguish them\nfrom traditional Kd-trees. The BOD-tree structure is the same as\nthe Kd-tree structure,as shown in Fig. 1(b), but it produces excellent\nload balancing between partitions.\nThe key idea of a BOD-tree index is to start with a partition\ncontaining all sample points and then split it into smaller partitions\nusing the node splitting algorithm in the corresponding Kd-tree.\nWhen splitting, we introduced new constraints to ensure that the\nutilization of leaf nodes does not exceed a pre-specified threshold,\ne.g., 90%, which guarantees that any record can be assigned to a\npartition, while keeping the partition no larger than the default\nblock size, e.g., 128MB. In addition, we do not completely split\naccording to the size of the node value, but also consider the data\nvolume of the node, which is mainly to solve the problem of data\ndistribution of abnormal nodes, as shown in the blue circles in\nFig. 1(b). This structure ensures partition load balancing.\nThe rest of this paper is organized as follows. Section 1 introduces\nthe background of ID indexing and then provides black-box Kd-tree\nindexing. Section 2 describes white-box BOD-tree indexes. Section 3\npresents the results of our experimental study and conclusion in\nSection 4.\n1 BLACK-BOX KD-TREE INDEXING\nIn this paper, the BOD-index indexing algorithm relies on a sampling-\nbased indexing method, which consists of three stages: sampling,\nboundary computation, and physical partitioning. Phase 1 draws a\nrandom sample of the input to infer its distribution. Phase 2 uses\nthis sample to divide the one-dimensional space and define the\npartition boundaries. Phase 3 partitions the data by assigning each\nrecord to one of the partitions. The focus of this work is on Phase\n2 and Phase 3.In this section, we propose the use of Kd-tree indexes for the\npreferred solution. This method customizes stage 2 in a sampling-\nbased index by using an existing Kd-tree index as a black box.\nIt first initializes an empty Kd-tree, while setting the maximum\nnode capacity \xf0\x9d\x91\x80=\xf0\x9d\x90\xb5\xc2\xb7\xf0\x9d\x91\xa0\xf0\x9d\x91\x8e\xf0\x9d\x91\x9a\xf0\x9d\x91\x9d\xf0\x9d\x91\x99\xf0\x9d\x91\x92\xf0\x9d\x91\x85\xf0\x9d\x91\x8e\xf0\x9d\x91\xa1\xf0\x9d\x91\x96\xf0\x9d\x91\x9c ,\xf0\x9d\x90\xb5is default block size and\n\xf0\x9d\x91\xa0\xf0\x9d\x91\x8e\xf0\x9d\x91\x9a\xf0\x9d\x91\x9d\xf0\x9d\x91\x99\xf0\x9d\x91\x92\xf0\x9d\x91\x85\xf0\x9d\x91\x8e\xf0\x9d\x91\xa1\xf0\x9d\x91\x96\xf0\x9d\x91\x9c is sampling ratio.\nThe Kd-tree implementation has two limitations. First, Kd-tree is\ndivided based on the size of the node value, smaller than the node\nvalue is divided into the left subtree, on the contrary, it is divided\ninto the right subtree. This partitioning rule is suitable for unique\nID partitioning and can produce perfectly balanced partitions. But\nfor partitions with duplicate IDs, it means that ID data with the\nsame value as multiple nodes will be uniquely divided into one\npartition.\nThe second limitation is that all leaf nodes are full, which means\nthat the capacity of the leaf nodes is close to the default block\nsize, which is an ideal feature, and the utilization of all nodes is\nclose to 100%. However, Kd-tree indexes are constructed based on\nsampling samples and may not fully cover the ID field, therefore, in\nthe physical partition, there may be data allocated to fully loaded\nleaf nodes.\n2 WHITE-BOX KD-TREE INDEXING\nThis section introduces a new white-box approach to implementing\nindexes, which we call BOD-trees. First, BOD-tree indexes over-\ncome the first limitation (the assignment of duplicate IDs) by adopt-\ning a novel improvement that allows us to assign duplicate IDs\nto multiple partitions to produce balanced partitions. Second, we\nadjust the capacity of each leaf node to 90% of the default block\nsize, which ensures that IDs uncovered during the sampling phase\ncan be safely partitioned into partitions without causing capacity\noverflow. Below, we focus on describing the balanced partitioning\nidea of BOD-tree indexes.\nThe key idea is to generate balanced partitions by preserving\nboth node value and node capacity, which is not allowed in tra-\nditional Kd-trees. For example, if the dataset size is 800 and the\npartition capacity is 100, a total of 8 partitions are required to store\ndata. As shown in Figure 1b, when using the traditional Kd-tree\nindex,\xf0\x9d\x91\x831=\xf0\x9d\x91\x832=\xf0\x9d\x91\x833=\xf0\x9d\x91\x834=0,\xf0\x9d\x91\x835=500,\xf0\x9d\x91\x836=\xf0\x9d\x91\x837=\xf0\x9d\x91\x838=100.\nHowever, through the reserved node value and node capacity, we\nneed to judge the following three conditions when looking for leaf\nnodes: 1) Whether the ID is less than the node value, if so, divide\nit into the left subtree; 2) The node value is equal to the ID value\nand the node capacity is not empty, if so, it is divided into the\nleft subtree; 3) Whether the ID is not less than the node value, if\nso, it is divided into the right subtree. For example, when \xf0\x9d\x90\xbc\xf0\x9d\x90\xb7=3\nis compared with the root node, \xf0\x9d\x90\xbc\xf0\x9d\x90\xb7=\xf0\x9d\x91\x89\xf0\x9d\x91\x8e\xf0\x9d\x91\x99\xf0\x9d\x91\xa2\xf0\x9d\x91\x92(\xf0\x9d\x91\x9b\xf0\x9d\x91\x9c\xf0\x9d\x91\x91\xf0\x9d\x91\x92\xf0\x9d\x90\xbc\xf0\x9d\x90\xb7)=3, and\n\xf0\x9d\x90\xb6\xf0\x9d\x91\x8e\xf0\x9d\x91\x9d\xf0\x9d\x91\x8e\xf0\x9d\x91\x90\xf0\x9d\x91\x96\xf0\x9d\x91\xa1\xf0\x9d\x91\xa6(\xf0\x9d\x91\x9b\xf0\x9d\x91\x9c\xf0\x9d\x91\x91\xf0\x9d\x91\x92\xf0\x9d\x90\xbc\xf0\x9d\x90\xb7)!=0. Therefore, the data will be divided into the\nleft subtree of the root node, while the traditional Kd-tree index\nwill be Divide that data into the right subtree.\nFor BOD-tree, we use a one-dimensional Kd-tree node splitting\nalgorithm. The algorithm first selects a split point. The split point\nselection is used as is, without any changes. The division is per-\nformed recursively on the two generated subintervals until the\ndesired number of divisions is generated, and all division points\nare recorded. Second, we calculate the abnormal data for each split'
