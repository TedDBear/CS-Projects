b'International Journal of Computer Vision (2023) 131:407\xe2\x80\x93430\nhttps://doi.org/10.1007/s11263-022-01706-5\nRobots Understanding Contextual Information in Human-Centered\nEnvironments Using Weakly Supervised Mask Data Distillation\nDaniel Dworakowski1\xc2\xb7Angus Fung1\xc2\xb7Goldie Nejat1\nReceived: 23 November 2020 / Accepted: 18 October 2022 / Published online: 11 November 2022\n\xc2\xa9 The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2022\nAbstract\nContextual information contained within human environments, such as text on signs, symbols and objects provide importantinformation for robots to use for exploration and navigation. To identify and segment contextual information from images\nobtained in these environments data-driven methods such as Convolutional Neural Networks (CNNs) can be used. However,\nthese methods require signi\xef\xac\x81cant amounts of human labeled data which is time-consuming to obtain. In this paper, we present the novel Weakly Supervised Mask Data Distillation (WeSuperMaDD) architecture for autonomously generating pseudo segmentation labels (PSLs) using CNNs not specifically trained for the task of text segmentation, for example, CNNs alternatively trained for: object classification or image captioning. WeSuperMaDD is uniquely able to generate PSLs using learned imagefeatures from datasets that are sparse and with limited diversity, which are common in robot navigation tasks in human-centredenvironments (i.e., malls, stores). Our proposed architecture uses a new mask re\xef\xac\x81nement system which automatically searches\nfor the PSL with the fewest foreground pixels that satis\xef\xac\x81es cost constraints. This removes the need for handcrafted heuristic\nrules. Extensive experiments were conducted to validate the performance of WeSuperMaDD in generating PSLs for datasetscontaining text of various scales, fonts, orientations, curvatures, and perspectives in several indoor/outdoor environments. A\ndetailed comparison study conducted with existing approaches found a signi\xef\xac\x81cant improvement in PSL quality. Furthermore,\nan instance segmentation CNN trained using the WeSuperMaDD architecture achieved measurable improvements in accuracywhen compared to an instance segmentation CNN trained with Na\xc3\xafve PSLs. We also found our method to have comparable\nperformance to existing text detection methods.\nKeywords Weakly supervised learning for robots \xc2\xb7Environment context identi\xef\xac\x81cation \xc2\xb7Segmentation and labeling \xc2\xb7Robot\nnavigation and exploration\n1 Introduction\nHuman-centered environments contain an abundance of con-\ntextual information such as text on signs, symbols, and\nobjects that are used as landmarks to help guide users with\nCommunicated by Frederic Jurie.\nB Daniel Dworakowski\ndaniel.dworakowski@mail.utoronto.ca\nAngus Fung\nangus.fung@mail.utoronto.ca\nGoldie Nejat\nnejat@mie.utoronto.ca\n1Autonomous Systems and Biomechatronics Laboratory(ASBLab), Department of Mechanical and IndustrialEngineering, University of Toronto, 5 King\xe2\x80\x99s College Road,Toronto, ON M5S 3G8, Canadapoint-to-point navigation in unknown environments (Vilar\net al., 2014 ), and update maps of the environment (Peng et al.,\n2018 ). Service robots working in varying human-centered\n(Dworakowski et al., 2021 ) environments can exploit these\ntypes of contextual information to aid with navigation. Forexample, robots can use text on aisle signs in grocery stores\nto determine which aisles to search for a particular item\n(Thompson et al., 2018 ). They have also used contextual\ninformation for mapping and localization. Namely by using\nan annotated map of an of\xef\xac\x81ce with room placards for goal\ndirected navigation (Case et al., 2011 ). Robots have also cre-\nated semantic maps using product locations (Cleveland et al.,2017 ), maps from unique text landmarks identi\xef\xac\x81ed in images\n(Wang et al., 2015 ), and have used salient objects identi\xef\xac\x81ed\nfrom learned features (e.g., edges, contours, etc.) for visual\n123'
b'408 International Journal of Computer Vision (2023) 131:407\xe2\x80\x93430\nodometry (Liang et al., 2019 ). These approaches rely specif-\nically on a robot\xe2\x80\x99s ability to identify and localize context inan environment.\nRecent work in the area of context detection and seg-\nmentation has made use of Convolutional Neural Networks(CNNs) to detect the presence of various types of objectsor text within images of an environment (He et al., 2017 ;\nZhang, et al., 2018 ; Radosavovic et al., 2018 ). However,\nthe amount of human effort required to generate the vastexpert labeled datasets required for training these existing\nnetworks signi\xef\xac\x81cantly increases the overall time cost of their\nuse. While some existing datasets do provide the labels nec-essary to train CNNs for segmentation tasks, they are limited\nin scope, and only target speci\xef\xac\x81c (e.g., people, animals)\nobjects, not necessarily applicable for contextual informationfor robotic exploration and navigation problems. For exam-ple, the widely used PASCAL VOC dataset only has 20 object\nclasses, mainly consisting of a limited set of people, animals,\nvehicles, and some indoor objects (Everingham et al., 2015 ).\nTherefore, CNNs trained with this dataset cannot be used\nto provide the large range of contextual information needed\nfor robots to interpret their environments for exploration andnavigation tasks. Other datasets provide larger numbers of\nclasses, however, again only a small portion of examples rel-\native to the number of classes are available. For example, theADE20k dataset (Zhou et al., 2019 ) contains 3,169 classes\nof people, vehicles, and objects in rooms, but only 270 of\nthe classes have more than 100 instances. Training CNNs to\naccurately segment large numbers of classes with a datasetsuch as ADE20k which has a long-tail class distribution is an\nopen challenge (Li et al., 2020 ). On the other hand, datasets\nsuch as the Waymo open dataset (Sun et al., 2019 ), Open\nImages (Benenson et al., 2019 ), and ICDAR-15,17 (Karatzas\net al., 2015 ; Nayef et al., 2017 ) contain several context cate-\ngories with many examples that can be used by robots, e.g.,text, cars, etc., but they are not fully labeled, requiring theclassi\xef\xac\x81cation of each pixel in an image in the dataset prior\nto training. Creating labels for all context instances within\nthese datasets is signi\xef\xac\x81cantly time consuming and must bedone manually. Past research has found that the time required\nto manually generate a segmentation label is approximately\n54 s per context instance (Jain & Grauman, 2013 ). Based on\nthis we can estimate that it would take 20 years to segment all\n2D objects in the Waymo open dataset! While transfer learn-\ning approaches using large-scale synthetic datasets such asSynthText (Gupta et al., 2016 ) can be used, these approaches\nstill require a fully annotated dataset with segmentation labels\nfrom real-world environments. For the Total-Text dataset\n(Ch\xe2\x80\x99ng and Chan 2017 ) with 11,459 text instances, this would\nrequire over 170 h of manual labeling.\nGiven the large investment needed to create these labels,\nseveral automated methods have been proposed to gener-ate pseudo segmentation labels (PSLs) to segment an inputimage and to replace human expert labels. In general, Na\xc3\xafve\nmethods have been proposed to avoid the human time cost ofper-pixel segmentation by: (1) using bounding box labels\n(Khoreva et al., 2017 ), or (2) generating soft labels (i.e.,\nlabels between 0 and 1) based on the assumed shape of con-text instances (Liu et al., 2019 ). However, these approaches\nrely on speci\xef\xac\x81c assumptions about the shape and structure\nof context instances that are not always valid, for example,\nassuming objects do not have holes (e.g., the center of thecharacter \xe2\x80\x98o\xe2\x80\x99).\nRecently, semi or weakly supervised learning methods\nhave been proposed to introduce learned features into thelabel generation process. Semi-supervised methods train a\nmodel using a dataset containing fully labeled and unla-\nbeled data to generate pseudo labels for the unlabeled subset(Chapelle et al., 2010 ). An example of semi-supervised learn-\ning is data distillation where the fully labeled subset of\na dataset is used to train a CNN. The CNN is then used\nto generate labels for unlabeled images using an ensembleof predictions from multiple transformed versions of each\nimage (Radosavovic et al., 2018 ). These methods, however,\nstill require human expert supervision to generate the labeledset. Alternatively, weakly supervised methods generate PSLs\nusing partial information such as class or bounding box labels\nto completely label a dataset (Zhou, 2017 ). For example,\nweakly supervised methods use techniques such as classpeak response (Zhou et al., 2018 ), adversarial erasing (Wei\net al., 2017\n), and Class Activation Maps (CAMs) (Saleh et al.,\n2018 ). However, these approaches can signi\xef\xac\x81cantly restrict\nthe types of CNNs that can be trained due to the use of special-\nized CNN layers which determine the contribution of pixels\nin the input image to the CNN\xe2\x80\x99s \xef\xac\x81nal output. For example,CAMs require an additional global average pooling layer fol-\nlowed by a fully connected layer. Requiring speci\xef\xac\x81c layers\nlimits the applicability of such existing weakly supervisedsegmentation methods since they cannot be generalized toall problems.\nTo avoid fully training a network, in (Khoreva et al.,\n2017 ), unsupervised segmentation methods, such as Grab-\nCut (Rother et al., 2004 ) were used. However, since this\nmethod is class agnostic, it results in signi\xef\xac\x81cant noise being\npresent in the generated labels, it reducing the performanceof the trained models compared to fully supervised models\n(Khoreva et al., 2017 ).\nAs robots must operate in different environments with\nvarying terrain, con\xef\xac\x81gurations, and objects, large datasetsmust be obtained to train a robust segmentation CNN for con-\ntext detection. The size of these datasets makes generating\nsegmentation labels time consuming and slow. Using weaklysupervised methods to generate PSLs is desirable as they do\nnot require fully labeled data and can therefore reduce manual\nlabeling effort. However, weakly supervised methods require\n123'
