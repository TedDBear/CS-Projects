b'Robust Real-time Face RecognitionB. Lagerwall\x00University of KwaZulu-NatalSchool of Mathematics, Statistics andComputer ScienceDurban, South Africa208506448@stu.ukzn.ac.zaS. Viriri\xe2\x80\xa0University of KwaZulu-NatalSchool of Mathematics, Statistics andComputer ScienceDurban, South Africaviriris@ukzn.ac.zaABSTRACT This paper describes and discusses the algorithms required to perform face detection and face recognition in real-time. Simple features, similar to Haar basis functions, areused for detection and the eigenfaces technique is used forrecognition. Further to the above, a novel method of in-creasing face recognition rates is presented for situationswhere a database containing multiple images of the samesubject is being used. It is shown that these well-known,existing techniques for both detection and recognition canbe combined in a manner that runs in real-time, but stillpreserves the original success rates mentioned in litera-ture.Categories and Subject DescriptorsI.5.3 [Pattern Recognition]: Miscellaneous\xe2\x80\x94algorithms;I.4.7 [Image Processing]: Metrics\xe2\x80\x94complexity measures,feature measurement.KeywordsFace recognition, Face detection, Real-time, Selection al-gorithm1. INTRODUCTIONThe process of obtaining the identity of a person froman image can be successfully performed by only lookingat their face. In fact, identifying a person can be bro-ken down into two distinct stages. Firstly, there is facedetection \xe2\x80\x93 which involves identifying any potential faceswithin the image. The second stage is face recognition \xe2\x80\x93which involves taking detected faces and classifying themusing an already existing database of faces.Both face detection and face recognition remain impor-tant topics in computer vision because of the large numberof real-world scenarios which they can be applied to. Asan example, some modern day digital cameras use facedetection to assist in their autofocus mechanism. Face\x00Brett Lagerwall, the Honours student.\xe2\x80\xa0Dr. Serestina Viriri, the supervisor.Permission to make digital or hard copies of all or part of this work forpersonal or classroom use is granted without fee provided that copies are notmade or distributed for pro\xef\xac\x81t or commercial advantage and that copies bearthis notice and the full citation on the \xef\xac\x81rst page. Copyrights for componentsof this work owned by others than ACM must be honored. Abstracting withcredit is permitted. To copy otherwise, or republish, to post on servers or toredistribute to lists, requires prior speci\xef\xac\x81c permission and/or a fee. Requestpermissions from Permissions@acm.org.SAICSIT\xe2\x80\x9913, October 07 - 09 2013, East London, South AfricaCopyright 2013 ACM 978-1-4503-2112-9/13/10 ...$15.00http://dx.doi.org/10.1145/2513456.2513494.recognition has been used to minimize fraud such as cast-ing multiple votes at an election and preventing a personfrom obtaining a fake identity document. A more modernusage of face recognition can be found in social networking\xe2\x80\x93s o m ew e b s i t e ss u c ha sF a c e b o o kw i l la u t o m a t i c a l l yd e -tect faces and try to predict which friend the face belongsto. However, arguably the most important usage of facedetection and recognition is found in security systems. Inparticular, it is imperative that detection and recognitionsystems used by CCTV cameras can be performed in real-time, since this will help to instantly put o\x00cials on thetrack of the suspect.2. RELATED WORKAn u m b e ro fd i\x00erent approaches have been used to per-form face detection. Viola and Jones [12] performed fea-ture extraction and these features were passed through acascade of classi\xef\xac\x81ers that were trained using the AdaBoosttechnique. The features that they used were rectangular.Rectangular features may seem limiting, however Violaand Jones argued that they allow for extremely e\x00cientcomputation.Rahman et al. [7] proposed a number of optimizationswhich could be applied to the Viola and Jones algorithm.Most importantly, they introduced the concept of a keyframe. This means that in a streaming image, detectionis only performed on one in everyxframes.Another well known detection technique is the neuralnetwork-based \xef\xac\x81lter introduced by Rowley et al. [8]. Thedetection rates of this system are comparable with the oneproposed by Viola and Jones, but the quoted executiontime for Rowley et al. is considerably longer [12, 8].One of the earliest techniques used in face recognitionwas performed by Turk and Pentland [11]. They usedPCA (Principal Component Analysis) to encode facial im-ages in what they call an information theory approach.Basically, all of the faces in a face database are manip-ulated to form a set of eigenvectors (eigenfaces in facerecognition literature [4]). Each of the original faces canbe reconstructed via linear combinations of the eigenvec-tors. An unknown face is then tested against the eigen-vectors to see which of the original faces it most closelyresembles.Moon and Phillips [4] attempt to improve on the eigen-faces technique by introducing various ideas and optimiza-tions. Most notably, they experiment with removing bothlower-order and higher-order eigenvectors and they try us-ing di\x00erent nearest-neighbour distance classi\xef\xac\x81ers. How-ever, recognition rates for frontal, upright facial images donot seem to dramatically increase.194\n'
b'\xef\x80\x81\xef\x80\x82\xef\x80\x83\xef\x80\x84\xef\x80\x85\xef\x80\x82\xef\x80\x86\xef\x80\x87\xef\x80\x88\xef\x80\x89\xef\x80\x8a\xef\x80\x8b\xef\x80\x82\xef\x80\x8c\xef\x80\x84\xef\x80\x8d\xef\x80\x84\xef\x80\x8a\xef\x80\x84\xef\x80\x8c\xef\x80\x8a\xef\x80\x8e\xef\x80\x8f\xef\x80\x87\xef\x80\x90\xef\x80\x81\xef\x80\x82\xef\x80\x91\xef\x80\x8c\xef\x80\x82\xef\x80\x92\xef\x80\x84\xef\x80\x93\xef\x80\x8f\xef\x80\x94\xef\x80\x81\xef\x80\x95\xef\x80\x82\xef\x80\x91\xef\x80\x91\xef\x80\x8e\xef\x80\x96\xef\x80\x84\xef\x80\x85\xef\x80\x91\xef\x80\x97\xef\x80\x98\xef\x80\x89\xef\x80\x8a\xef\x80\x88\xef\x80\x89\xef\x80\x8a\xef\x80\x99\xef\x80\x81\xef\x80\x82\xef\x80\x88\xef\x80\x8a\xef\x80\x89\xef\x80\x85\xef\x80\x84\xef\x80\x92\xef\x80\x86\xef\x80\x83\xef\x80\x82\xef\x80\x9a\xef\x80\x84\xef\x80\x8b\xef\x80\x82\xef\x80\x8c\xef\x80\x84\xef\x80\x9b\xef\x80\x84\xef\x80\x8c\xef\x80\x8f\xef\x80\x9a\xef\x80\x87\xef\x80\x8e\xef\x80\x8a\xef\x80\x8e\xef\x80\x8f\xef\x80\x87\xef\x80\x90\xef\x80\x9c\xef\x80\x8e\xef\x80\x9a\xef\x80\x84\xef\x80\x87\xef\x80\x94\xef\x80\x82\xef\x80\x8c\xef\x80\x84\xef\x80\x91\xef\x80\x97\xef\x80\x98\xef\x80\x89\xef\x80\x8a\xef\x80\x88\xef\x80\x89\xef\x80\x8a\xef\x80\x99\xef\x80\x9d\xef\x80\x82\xef\x80\x83\xef\x80\x84Figure 1: Subsystem Interaction.3. DESIGN AND METHODOLOGYThe proposed system can be decomposed into three sub-systems \xe2\x80\x93 namely face detection, face recognition and syn-chronizing with a camera in real time. The interactionbetween these main subsystems as well as the outputs ob-tained from them can be seen in Figure 1. The design andimplementation of the detection and recognition subsys-tems as well as the novel idea for improving recognitionrates are described below.3.1 Face DetectionThe face detection algorithm is based on the work fromViola and Jones in [12] \xe2\x80\x93 mainly because of its fast execu-tion speed.3.1.1 Classi\xef\xac\x81erThe \xef\xac\x81rst step towards building a detection system isto train a classi\xef\xac\x81er. Viola and Jones [12] used AdaBoostfor training although they mentioned that other machinelearning techniques may be just as e\x00ective. One draw-back to building a classi\xef\xac\x81er is the sheer amount of train-ing data required (5000 facial images and 10000 non-facialimages in Viola and Jones). It was also mentioned thattraining time for the classi\xef\xac\x81er was in the order of weeks(although technological advancements would greatly re-duce that today). For successful real-time face detec-tion, it is only necessary to use a classi\xef\xac\x81er \xe2\x80\x93 not neces-sarily build it. Thus, because of the drawbacks mentionedabove an already available classi\xef\xac\x81er is used: the haarcas-cadefrontalfacedefault provided with OpenCV [2].3.1.2 PreprocessingThe only preprocessing performed on the image is con-verting it to grayscale. ImageJ [1] is used to aid in the con-version. Variance normalization is not performed on theimage as a whole, but during the process of the algorithm,it is applied on each sub-window, where a sub-window isde\xef\xac\x81ned by Viola and Jones [12] to be the portion of theimage which is to be classi\xef\xac\x81ed as a face or non-face.3.1.3 FeaturesIt has been shown in Viola and Jones [12] that rectan-gular features can be used to represent and detect a faceif enough rectangles are identi\xef\xac\x81ed.3.1.4 Integral ImageThe integral image at a particular pixel is de\xef\xac\x81ned tobe the sum of the pixels above and to the left of thatparticular pixel. Thus, mathematically the integral imageat position (x, y)c a nb ed e \xef\xac\x81 n e da s :ii(x, y)=Xa\x00xXb\x00yi(a, b)(1)where ii(x, y) is the value of the integral image at (x, y)and i(a, b) is the value of the original image at (a, b).The advantage of calculating the integral image for eachpixel is that calculating the value of a rectangular featurecan be done in 4 array references. If the top left cornerof the rectangle is at position (x1,y1)a n dt h eb o t t o mright corner is at (x2,y2), then the value of the rectangularfeature is:rect=ii(x1,y1)\x00ii(x1,y2)\x00ii(x2,y1)+ii(x2,y2)( 2 )3.1.5 Passing the Classi\xef\xac\x81erThe classi\xef\xac\x81er being used consists of a number of stagesand each stage consists of a number of features. At aparticular stage, a sub-window can only pass that stage ifthe sum of the values generated by testing various features(speci\xef\xac\x81ed in the haarcascadefrontalfacedefault classi\xef\xac\x81er)is above a certain threshold. For the sub-window to beconsidered as a face, it must pass all 25 stages.3.1.6 Merging DetectionsViola and Jones [12] said that they merged all overlap-ping detections. However, if two faces are close togetherthis could accidentally be counted as a single detection.Instead, a merging algorithm partially based on work doneby Rowley et al. in [9] was constructed. For each pair ofrectanglesiandj, the rectangles can be said to be detect-ing the same face if both (3) and (4) hold.euclideanDistance(ci,cj)\x00t\x00width(i)( 3 )euclideanDistance(ci,cj)\x00t\x00width(j)( 4 )whereciis the centre of rectanglei,cjis the centre ofrectanglejandtis a threshold chosen to be 0.2 [9].3.1.7 ImprovementsViola and Jones [12] de\xef\xac\x81ne a scaling factor to be thefactor which the sub-window is incremented after a com-plete iteration or sweep over the image. In their paper,they mention using a scaling factor ofs=1.25. How-ever, on implementation it was found that using a smallerscaling factor ofs=1.1 improves the detection rate. Itshould, however, be noted that this comes at the cost ofan increase in execution time.3.2 Face RecognitionThe eigenfaces technique is used for face recognition.One of the key advantages of this algorithm is the veryquick classi\xef\xac\x81cation of the probe/test image.3.2.1 TrainingRecognition must be performed against a base set ofknown images. This set is typically called the trainingset. On each image in the training set, illumination nor-malization is performed using:imagei=imageimax(5)195'
